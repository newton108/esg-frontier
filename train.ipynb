{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import re\n",
    "import spacy\n",
    "from spacy.tokens import DocBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_tweets_to_pd(jsonfile):\n",
    "    '''\n",
    "    read paginated json file to df\n",
    "    input (string): .json file created by searchtweets module\n",
    "    output (pd.DataFrame)\n",
    "    '''\n",
    "    raw_df = pd.read_json(jsonfile, lines=True)\n",
    "    df = pd.DataFrame()\n",
    "    for page in raw_df['data']:\n",
    "        df = pd.concat([df, pd.DataFrame(page)])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15464 entries, 0 to 499\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    15464 non-null  string\n",
      "dtypes: string(1)\n",
      "memory usage: 241.6 KB\n"
     ]
    }
   ],
   "source": [
    "df_positive = json_tweets_to_pd('get_tweets/tweets_positive.json')\n",
    "\n",
    "# drop tweets withheld by the twitter accounts\n",
    "df_positive = df_positive.drop(df_positive[df_positive.withheld.notnull()].index)\n",
    "\n",
    "df_positive.drop(columns=['id', 'withheld'], inplace=True)\n",
    "df_positive = df_positive.astype({'text':'string'})\n",
    "df_positive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 186204 entries, 0 to 186203\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    186204 non-null  string\n",
      "dtypes: string(1)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "df_tweets = pd.read_csv('data/tweets_dow.csv', usecols = ['text'], dtype={'text':'string'})\n",
    "df_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_positive = len(df_positive)\n",
    "df_positive['climate_related'] = np.ones(n_positive, dtype=bool)\n",
    "\n",
    "df_negative = df_tweets.sample(n_positive, random_state = 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keywords = [\"climate action\", \"environment\", \"climate change\", \"renewable\", \"recycle\", \"earth\", \"emission\", \"carbon footprint\", ...]\n",
    "with open(\"keywords.txt\", \"r\") as f:\n",
    "    keywords = [line.rstrip() for line in f]\n",
    "negative = df_negative.text.apply(lambda text: not any([keyword in text.lower() for keyword in keywords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative = df_negative[negative]\n",
    "df_negative['climate_related'] = np.zeros(len(df_negative), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_positive, df_negative]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(tweet): \n",
    "\n",
    "    parsed_tweet = tweet\n",
    "    \n",
    "    # remove url\n",
    "    parsed_tweet = re.sub(r\"\\S*https?:\\S*\", \"\", parsed_tweet, flags=re.MULTILINE)\n",
    "\n",
    "    # remove non-ascii\n",
    "    parsed_tweet = re.sub(r\"[^\\x00-\\x7F]+\", \"\", parsed_tweet)\n",
    "\n",
    "    # remove 'RT'\n",
    "    parsed_tweet = re.sub(r\"^RT\\s\", \"\", parsed_tweet)\n",
    "    return parsed_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, embed):\n",
    "    '''\n",
    "    Preprocess the dataframe into spacy pipeline for later classification\n",
    "    ---\n",
    "    Input:\n",
    "    df (DataFrame): Pandas dataframe containing the raw text and outputs.\n",
    "    embed (str): Name of pipeline embedding used\n",
    "\n",
    "    Output:\n",
    "    df (DataFrame): Preprocessed input dataframe\n",
    "    docs (doc): SpaCy doc object that stores text data along with classification\n",
    "    '''\n",
    "\n",
    "    # clean up tweets\n",
    "    df.text = df.text.apply(clean_up)\n",
    "\n",
    "    # Store the data into tuples\n",
    "    data = tuple(zip(df.text.tolist(), df.climate_related.tolist())) \n",
    "    \n",
    "    # Load English library from SpaCy\n",
    "    nlp = spacy.load(embed)\n",
    "    print(data[0])\n",
    "\n",
    "    # Storage for docs\n",
    "    docs = []\n",
    "\n",
    "    # One-hot encoding for the classifications\n",
    "    for doc, label in tqdm(nlp.pipe(data, as_tuples=True), total = len(data)):\n",
    "        \n",
    "        if label:\n",
    "            doc.cats['climate_related'] = 1\n",
    "        else:\n",
    "            doc.cats['climate_related'] = 0\n",
    "        # print(doc.cats)\n",
    "        \n",
    "        docs.append(doc)\n",
    "    return df, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 24430 Valid: 6108\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, valid_df = train_test_split(df, test_size=0.2)\n",
    "\n",
    "print(\"Train:\",len(train_df), \"Valid:\", len(valid_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the model in installed in current conda env\n",
    "\n",
    "# embed = \"en_core_web_sm\"\n",
    "# embed = \"en_core_web_md\"\n",
    "# embed = \"en_core_web_lg\"\n",
    "embed = \"en_core_web_trf\"\n",
    "\n",
    "assert spacy.util.is_package(embed), embed + \" is not installed. To install, run: `!python -m spacy download \\\"\" + embed + \"\\\"`\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('@aster_cloud: Want Faster Data And A Cleaner Planet? Start Mining Asteroids - \\n\\n#planet #Data #ClimateCrisis #Research #technology\\n\\nhttp', True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24430 [00:00<?, ?it/s]/Users/joe/miniconda3/envs/esg-frontier/lib/python3.10/site-packages/torch/autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "100%|██████████| 24430/24430 [1:21:48<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"@Ym78200: Want to look at the world with fresh eyes?\\n\\nSo, let's meet at #Vivatech, 15-18 june,\\non @3DEXPERIENCELab booth K52,\\nand let's\", True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6108/6108 [44:38<00:00,  2.28it/s]  \n"
     ]
    }
   ],
   "source": [
    "# Covert the train and valid dataframes to .spacy files for training\n",
    "\n",
    "# Preprocess the dataframes for train data\n",
    "train_data, train_docs = preprocess(train_df, embed)\n",
    "# # Save data and docs in a binary file to disc\n",
    "doc_bin = DocBin(docs=train_docs)\n",
    "doc_bin.to_disk(\"./spacy_data/textcat_train.spacy\")\n",
    "\n",
    "# # Preprocess the dataframes for validation data\n",
    "valid_data, valid_docs = preprocess(valid_df, embed)\n",
    "# # Save data and docs in a binary file to disc\n",
    "doc_bin = DocBin(docs=valid_docs)\n",
    "doc_bin.to_disk(\"./spacy_data/textcat_valid.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
      "- Language: en\n",
      "- Pipeline: textcat_multilabel\n",
      "- Optimize for: efficiency\n",
      "- Hardware: CPU\n",
      "- Transformer: None\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init config \"./config.cfg\" --lang en --pipeline textcat_multilabel --optimize efficiency --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "[2022-06-15 19:17:46,125] [DEBUG] Config overrides from CLI: ['paths.train', 'paths.dev']\n",
      "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2022-06-15 19:17:46,667] [INFO] Set up nlp object from config\n",
      "[2022-06-15 19:17:46,676] [DEBUG] Loading corpus from path: spacy_data/textcat_valid.spacy\n",
      "[2022-06-15 19:17:46,677] [DEBUG] Loading corpus from path: spacy_data/textcat_train.spacy\n",
      "[2022-06-15 19:17:46,678] [INFO] Pipeline: ['textcat_multilabel']\n",
      "[2022-06-15 19:17:46,680] [INFO] Created vocabulary\n",
      "[2022-06-15 19:17:46,681] [INFO] Finished initializing nlp object\n",
      "[2022-06-15 19:17:57,346] [INFO] Initialized pipeline components: ['textcat_multilabel']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[2022-06-15 19:17:57,407] [DEBUG] Loading corpus from path: spacy_data/textcat_valid.spacy\n",
      "[2022-06-15 19:17:57,409] [DEBUG] Loading corpus from path: spacy_data/textcat_train.spacy\n",
      "[2022-06-15 19:17:57,436] [DEBUG] Removed existing output directory: output/model-best\n",
      "[2022-06-15 19:17:57,459] [DEBUG] Removed existing output directory: output/model-last\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       68.34    0.68\n",
      "  0     200          41.13       93.52    0.94\n",
      "  0     400          28.65       95.25    0.95\n",
      "  0     600          22.27       96.31    0.96\n",
      "  0     800          19.95       97.06    0.97\n",
      "  0    1000          16.19       97.82    0.98\n",
      "  0    1200          14.57       98.25    0.98\n",
      "  0    1400          12.70       98.56    0.99\n",
      "  0    1600          10.71       98.84    0.99\n",
      "  0    1800          10.27       99.02    0.99\n",
      "  0    2000           8.78       99.27    0.99\n",
      "  1    2200           6.44       99.34    0.99\n",
      "  1    2400           5.61       99.44    0.99\n",
      "  1    2600           4.96       99.52    1.00\n",
      "  2    2800           4.39       99.58    1.00\n",
      "  2    3000           3.41       99.62    1.00\n",
      "  2    3200           3.28       99.66    1.00\n",
      "  3    3400           2.96       99.66    1.00\n",
      "  3    3600           2.27       99.69    1.00\n",
      "  3    3800           2.39       99.72    1.00\n",
      "  3    4000           2.14       99.73    1.00\n",
      "  4    4200           1.76       99.74    1.00\n",
      "  4    4400           1.67       99.76    1.00\n",
      "  4    4600           1.51       99.76    1.00\n",
      "  5    4800           1.26       99.78    1.00\n",
      "  5    5000           1.22       99.78    1.00\n",
      "  5    5200           1.13       99.78    1.00\n",
      "  6    5400           1.16       99.78    1.00\n",
      "  6    5600           0.92       99.79    1.00\n",
      "  6    5800           0.92       99.80    1.00\n",
      "  7    6000           0.79       99.80    1.00\n",
      "  7    6200           0.76       99.80    1.00\n",
      "  7    6400           0.67       99.81    1.00\n",
      "  8    6600           0.75       99.82    1.00\n",
      "  8    6800           0.56       99.81    1.00\n",
      "  8    7000           0.52       99.82    1.00\n",
      "  8    7200           0.62       99.82    1.00\n",
      "  9    7400           0.48       99.82    1.00\n",
      "  9    7600           0.45       99.82    1.00\n",
      "  9    7800           0.44       99.82    1.00\n",
      " 10    8000           0.36       99.82    1.00\n",
      " 10    8200           0.35       99.82    1.00\n",
      " 10    8400           0.35       99.82    1.00\n",
      " 11    8600           0.33       99.83    1.00\n",
      " 11    8800           0.27       99.83    1.00\n",
      " 11    9000           0.29       99.83    1.00\n",
      " 12    9200           0.28       99.83    1.00\n",
      " 12    9400           0.21       99.83    1.00\n",
      " 12    9600           0.24       99.83    1.00\n",
      " 12    9800           0.24       99.83    1.00\n",
      " 13   10000           0.20       99.83    1.00\n",
      " 13   10200           0.17       99.83    1.00\n",
      " 13   10400           0.19       99.83    1.00\n",
      " 14   10600           0.15       99.83    1.00\n",
      " 14   10800           0.15       99.83    1.00\n",
      " 14   11000           0.15       99.83    1.00\n",
      " 15   11200           0.16       99.83    1.00\n",
      " 15   11400           0.12       99.83    1.00\n",
      " 15   11600           0.12       99.83    1.00\n",
      " 16   11800           0.12       99.83    1.00\n",
      " 16   12000           0.09       99.83    1.00\n",
      " 16   12200           0.13       99.83    1.00\n",
      " 17   12400           0.10       99.83    1.00\n",
      " 17   12600           0.09       99.83    1.00\n",
      " 17   12800           0.08       99.83    1.00\n",
      " 17   13000           0.09       99.83    1.00\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output/model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train ./config.cfg --output ./output --paths.train ./spacy_data/textcat_train.spacy --paths.dev ./spacy_data/textcat_valid.spacy --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "79fabbbd37ad3894f6cfb0be2f75783fc59e43226a3dc1366dded6fba97273cc"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('esg-frontier')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
